{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dbispipeline.analytics import get_results_as_dataframe\n",
    "from mediaeval2020.analytics import extract_best_epoch\n",
    "from mediaeval2020.analytics import extract_best_outcome\n",
    "from mediaeval2020.analytics import extract_final_outcome\n",
    "from mediaeval2020.analytics import extract_metrics\n",
    "from mediaeval2020.analytics import plot_per_label\n",
    "from mediaeval2020.analytics import print_per_label\n",
    "\n",
    "\n",
    "results = get_results_as_dataframe(project_name='mediaeval2020')\n",
    "\n",
    "row = results[results['id'] == 484].iloc[0]\n",
    "outcome = copy.deepcopy(row['outcome'])\n",
    "\n",
    "for _, v in outcome.items():\n",
    "    for k in list(v.keys()):\n",
    "        if ('all' in k) or ('confusion_matrix' in k):\n",
    "            del v[k]\n",
    "\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'f1_macro'\n",
    "\n",
    "results['final_outcome'] = results['outcome'].apply(extract_final_outcome)\n",
    "results['best_outcome'] = results['outcome'].apply(lambda v: extract_best_outcome(v, metric=metric))\n",
    "results['best_epoch'] = results['outcome'].apply(lambda v: extract_best_epoch(v, metric=metric))\n",
    "\n",
    "def display_outcome(col):\n",
    "    outcome = []\n",
    "    for _, row in results.iterrows():\n",
    "        out = copy.deepcopy(row[col])\n",
    "        del out['confusion_matrix']\n",
    "        del out['average_precision_all']\n",
    "        del out['roc_auc_all']\n",
    "        out['id'] = row['id']\n",
    "        outcome.append(out)\n",
    "\n",
    "    outcome = pd.DataFrame(outcome).merge(results[['id', 'sourcefile']], on=['id'])\n",
    "    outcome['name'] = outcome['id'].apply(str) + ' ' + outcome['sourcefile']\n",
    "    outcome[['name', 'f1_micro', 'f1_macro', 'average_precision', 'precision_micro', 'precision_macro']].plot.bar(x='name', title=col, figsize=(12,6))\n",
    "    plt.show()\n",
    "\n",
    "results = results.sort_values(by=['id'])\n",
    "display(results[['id', 'best_epoch']])\n",
    "display_outcome('final_outcome')\n",
    "\n",
    "display_outcome('best_outcome')\n",
    "display(pd.json_normalize(results['best_outcome']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = results[results['id'] == 502].iloc[0]\n",
    "\n",
    "data = extract_metrics(row)\n",
    "print_per_label(data.sort_values(by=['pr-auc']))\n",
    "plt.show()\n",
    "\n",
    "display(data.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
